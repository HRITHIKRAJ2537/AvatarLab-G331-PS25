{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57234756-900c-454f-9c72-20c13dcf898c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025.03.25\n",
      "ffmpeg version 6.1.1-3ubuntu5 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "built with gcc 13 (Ubuntu 13.2.0-23ubuntu3)\n",
      "configuration: --prefix=/usr --extra-version=3ubuntu5 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --disable-omx --enable-gnutls --enable-libaom --enable-libass --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libharfbuzz --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-openal --enable-opencl --enable-opengl --disable-sndio --enable-libvpl --disable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-ladspa --enable-libbluray --enable-libjack --enable-libpulse --enable-librabbitmq --enable-librist --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libx264 --enable-libzmq --enable-libzvbi --enable-lv2 --enable-sdl2 --enable-libplacebo --enable-librav1e --enable-pocketsphinx --enable-librsvg --enable-libjxl --enable-shared\n",
      "libavutil      58. 29.100 / 58. 29.100\n",
      "libavcodec     60. 31.102 / 60. 31.102\n",
      "libavformat    60. 16.100 / 60. 16.100\n",
      "libavdevice    60.  3.100 / 60.  3.100\n",
      "libavfilter     9. 12.100 /  9. 12.100\n",
      "libswscale      7.  5.100 /  7.  5.100\n",
      "libswresample   4. 12.100 /  4. 12.100\n",
      "libpostproc    57.  3.100 / 57.  3.100\n",
      "Processing 1 HDTF videos...\n",
      "Successfully processed video 1/1\n",
      "Processing videos through pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1.1-3ubuntu5 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 13 (Ubuntu 13.2.0-23ubuntu3)\n",
      "  configuration: --prefix=/usr --extra-version=3ubuntu5 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --disable-omx --enable-gnutls --enable-libaom --enable-libass --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libharfbuzz --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-openal --enable-opencl --enable-opengl --disable-sndio --enable-libvpl --disable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-ladspa --enable-libbluray --enable-libjack --enable-libpulse --enable-librabbitmq --enable-librist --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libx264 --enable-libzmq --enable-libzvbi --enable-lv2 --enable-sdl2 --enable-libplacebo --enable-librav1e --enable-pocketsphinx --enable-librsvg --enable-libjxl --enable-shared\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'data_processing/specified_formats/videos/videos_25fps/FAzSK8PLmGI.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.16.100\n",
      "  Duration: 00:00:05.08, start: 0.000000, bitrate: 365 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 484x484 [SAR 1:1 DAR 1:1], 228 kb/s, 25 fps, 25 tbr, 12800 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 129 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, image2, to 'talking_face_preprocessing/processed_data/frames/FAzSK8PLmGI/%06d.png':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.16.100\n",
      "  Stream #0:0(und): Video: png, rgb24(pc, gbr/bt709/bt709, progressive), 484x484 [SAR 1:1 DAR 1:1], q=2-31, 200 kb/s, 25 fps, 25 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 png\n",
      "[out#0/image2 @ 0x608ce5f92100] video:47886kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "frame=  127 fps=0.0 q=-0.0 Lsize=N/A time=00:00:05.04 bitrate=N/A speed=17.3x    \n",
      "/home/hrithik-raj/myenv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hrithik-raj/myenv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 10/10 [00:00<00:00, 166440.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing images in talking_face_preprocessing/processed_data/faces/CarolynMaloney2_0 to 256x256...\n",
      "Resized 000005.png to 256x256\n",
      "Resized 000004.png to 256x256\n",
      "Resized 000003.png to 256x256\n",
      "Resized 000002.png to 256x256\n",
      "Resized 000010.png to 256x256\n",
      "Resized 000007.png to 256x256\n",
      "Resized 000009.png to 256x256\n",
      "Resized 000008.png to 256x256\n",
      "Resized 000006.png to 256x256\n",
      "Resized 000001.png to 256x256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hrithik-raj/myenv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/hrithik-raj/myenv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Processing clips:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 10 images in talking_face_preprocessing/processed_data/frames/CarolynMaloney2_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 2/10 [00:00<00:00, 14.77it/s]\u001b[A\n",
      " 40%|████      | 4/10 [00:00<00:00, 15.87it/s]\u001b[A\n",
      " 60%|██████    | 6/10 [00:00<00:00, 14.75it/s]\u001b[A\n",
      "Processing clips:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hrithik-raj/Project/talking_face_preprocessing/extract_frame_landmarks.py\", line 98, in <module>\n",
      "    main(args.from_dir, args.lmd_output_dir, args.skip_existing, args.check_and_padding)\n",
      "  File \"/home/hrithik-raj/Project/talking_face_preprocessing/extract_frame_landmarks.py\", line 68, in main\n",
      "    landmarks, bboxes = torchlm.runtime.forward(frame)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrithik-raj/myenv/lib/python3.12/site-packages/torchlm/runtime/_wrappers.py\", line 120, in forward\n",
      "    return RuntimeWrapper.forward(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrithik-raj/myenv/lib/python3.12/site-packages/torchlm/runtime/_wrappers.py\", line 50, in forward\n",
      "    bboxes = cls.face_base.apply_detecting(image, **kwargs)  # (n,5) x1,y1,x2,y2,score\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrithik-raj/myenv/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrithik-raj/myenv/lib/python3.12/site-packages/torchlm/tools/_faceboxesv2.py\", line 322, in apply_detecting\n",
      "    out = self.net(image_scale)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrithik-raj/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrithik-raj/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrithik-raj/myenv/lib/python3.12/site-packages/torchlm/tools/_faceboxesv2.py\", line 146, in forward\n",
      "    x = self.conv7_2(x)\n",
      "        ^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrithik-raj/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrithik-raj/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrithik-raj/myenv/lib/python3.12/site-packages/torchlm/tools/_faceboxesv2.py\", line 26, in forward\n",
      "    x = self.conv(x)\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"/home/hrithik-raj/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrithik-raj/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrithik-raj/myenv/lib/python3.12/site-packages/torch/nn/modules/conv.py\", line 554, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/hrithik-raj/myenv/lib/python3.12/site-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n",
      "    return F.conv2d(\n",
      "           ^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 238\u001b[39m\n\u001b[32m    235\u001b[39m     exit(\u001b[32m1\u001b[39m)\n\u001b[32m    237\u001b[39m num_videos_to_process = \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# Change this to process more videos\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_videos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_videos_to_process\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 224\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(num_videos)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;66;03m# Process all clips through the pipeline\u001b[39;00m\n\u001b[32m    223\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProcessing videos through pipeline...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m \u001b[43mprocess_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_video_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProcessing complete!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 180\u001b[39m, in \u001b[36mprocess_videos\u001b[39m\u001b[34m(video_files, base_dir)\u001b[39m\n\u001b[32m    174\u001b[39m     \u001b[38;5;66;03m# Third command: Extract frame landmarks\u001b[39;00m\n\u001b[32m    175\u001b[39m cmd3 = (\n\u001b[32m    176\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpython extract_frame_landmarks.py \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    177\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--from_dir \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframes_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    178\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--lmd_output_dir \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlandmarks_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    179\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:550\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    552\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:1201\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1199\u001b[39m         stderr = \u001b[38;5;28mself\u001b[39m.stderr.read()\n\u001b[32m   1200\u001b[39m         \u001b[38;5;28mself\u001b[39m.stderr.close()\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1203\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:1264\u001b[39m, in \u001b[36mPopen.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1262\u001b[39m     endtime = _time() + timeout\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1266\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1267\u001b[39m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[32m   1269\u001b[39m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[32m   1270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:2053\u001b[39m, in \u001b[36mPopen._wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   2051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.returncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2052\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2053\u001b[39m (pid, sts) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2054\u001b[39m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[32m   2055\u001b[39m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[32m   2056\u001b[39m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[32m   2057\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pid == \u001b[38;5;28mself\u001b[39m.pid:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:2011\u001b[39m, in \u001b[36mPopen._try_wait\u001b[39m\u001b[34m(self, wait_flags)\u001b[39m\n\u001b[32m   2009\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[32m   2010\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2011\u001b[39m     (pid, sts) = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2012\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[32m   2013\u001b[39m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[32m   2014\u001b[39m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[32m   2015\u001b[39m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[32m   2016\u001b[39m     pid = \u001b[38;5;28mself\u001b[39m.pid\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from PIL import Image\n",
    "\n",
    "# Define base directory\n",
    "base_path = \"talking_face_preprocessing\"\n",
    "hdtf_dir = os.path.join(base_path, \"HDTF\")\n",
    "dataset_dir = os.path.join(hdtf_dir, \"HDTF_dataset\")\n",
    "raw_video_dir = os.path.join(base_path, \"raw_videos\")\n",
    "clips_dir = os.path.join(base_path, \"clips\")\n",
    "video_dir = os.path.join(base_path, \"assets/video\")\n",
    "\n",
    "# HDTF dataset files\n",
    "video_url_path = os.path.join(dataset_dir, \"WDA_video_url.txt\")\n",
    "annotation_time_path = os.path.join(dataset_dir, \"WDA_annotion_time.txt\")  # Fixed typo from \"annotion\" to \"annotation\"\n",
    "\n",
    "def get_video_annotations(video_name, annotation_file):\n",
    "    annotations = {}\n",
    "    try:\n",
    "        with open(annotation_file, \"r\", encoding='utf-8-sig') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split(\" \")\n",
    "                if len(parts) > 1:\n",
    "                    video = parts[0]\n",
    "                    times = parts[1:]\n",
    "                    annotations[video] = times\n",
    "                    if video.endswith('.mp4'):\n",
    "                        annotations[video[:-4]] = times\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Annotation file {annotation_file} not found.\")\n",
    "        return []\n",
    "    variations = [video_name, video_name + '.mp4', video_name.replace('.mp4', '')]\n",
    "    for variation in variations:\n",
    "        if variation in annotations:\n",
    "            return annotations[variation]\n",
    "    lower_video_name = video_name.lower()\n",
    "    for key in annotations:\n",
    "        if key.lower() == lower_video_name or key.lower() == lower_video_name + '.mp4':\n",
    "            return annotations[key]\n",
    "    return []\n",
    "\n",
    "def process_hdtf_video(video_name, url):\n",
    "    downloaded_video = os.path.join(raw_video_dir, f\"{video_name}.mp4\")\n",
    "    if not os.path.exists(downloaded_video):\n",
    "        print(f\"Downloading HDTF video {video_name} from {url}\")\n",
    "        cmd = (\n",
    "            f'yt-dlp '\n",
    "            f'-f \"bestvideo[height<=1080]+bestaudio/best\" '\n",
    "            f'-o \"{downloaded_video}\" '\n",
    "            f'--merge-output-format mp4 \"{url}\"'\n",
    "        )\n",
    "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "        if result.returncode != 0:\n",
    "            print(f\"Failed to download {video_name}: {result.stderr}\")\n",
    "            return None\n",
    "\n",
    "    if not os.path.exists(downloaded_video):\n",
    "        print(f\"Download failed for {video_name}\")\n",
    "        return None\n",
    "\n",
    "    annotations = get_video_annotations(video_name, annotation_time_path)\n",
    "    if not annotations:\n",
    "        print(f\"No annotations found for {video_name}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    clip_outputs = []\n",
    "    for idx, timestamp in enumerate(annotations):\n",
    "        start, end = timestamp.split('-')\n",
    "        clip_output = os.path.join(clips_dir, f\"{video_name}_{idx}.mp4\")\n",
    "        if not os.path.exists(clip_output):\n",
    "            cmd = (\n",
    "                f'ffmpeg -i \"{downloaded_video}\" '\n",
    "                f'-ss {start} -to {end} '\n",
    "                f'-c copy \"{clip_output}\" -y'\n",
    "            )\n",
    "            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "            if result.returncode != 0:\n",
    "                print(f\"Failed to extract clip: {result.stderr}\")\n",
    "                return None\n",
    "        clip_outputs.append(clip_output)\n",
    "    \n",
    "    # Move clips to video_dir for further processing\n",
    "    video_files = []\n",
    "    for clip in clip_outputs:\n",
    "        video_file = os.path.join(video_dir, os.path.basename(clip))\n",
    "        os.rename(clip, video_file)\n",
    "        video_files.append(os.path.basename(video_file))\n",
    "    return video_files\n",
    "\n",
    "def resize_images_to_256x256(directory):\n",
    "    \"\"\"Resize all images in the given directory to 256x256 while maintaining aspect ratio.\"\"\"\n",
    "    target_size = (256, 256)\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                img = Image.open(file_path)\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                \n",
    "                orig_width, orig_height = img.size\n",
    "                aspect_ratio = orig_width / orig_height\n",
    "                \n",
    "                if aspect_ratio > 1:\n",
    "                    new_height = 256\n",
    "                    new_width = int(new_height * aspect_ratio)\n",
    "                else:\n",
    "                    new_width = 256\n",
    "                    new_height = int(new_width / aspect_ratio)\n",
    "                \n",
    "                img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "                new_img = Image.new('RGB', target_size, (0, 0, 0))\n",
    "                \n",
    "                paste_x = (256 - new_width) // 2\n",
    "                paste_y = (256 - new_height) // 2\n",
    "                \n",
    "                if new_width > 256 or new_height > 256:\n",
    "                    left = (new_width - 256) // 2\n",
    "                    top = (new_height - 256) // 2\n",
    "                    right = left + 256\n",
    "                    bottom = top + 256\n",
    "                    img_resized = img_resized.crop((left, top, right, bottom))\n",
    "                    new_img = img_resized\n",
    "                else:\n",
    "                    new_img.paste(img_resized, (paste_x, paste_y))\n",
    "                \n",
    "                new_img.save(file_path, quality=95)\n",
    "                print(f\"Resized {filename} to 256x256\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error resizing {filename}: {e}\")\n",
    "\n",
    "def process_videos(video_files, base_dir):\n",
    "    \"\"\"Process downloaded videos with the specified pipeline.\"\"\"\n",
    "    video_dir = os.path.join(base_dir, \"assets/video\")\n",
    "    audio_dir = os.path.join(base_dir, \"processed_data/audio\")\n",
    "    frames_dir = os.path.join(base_dir, \"processed_data/frames\")\n",
    "    faces_dir = os.path.join(base_dir, \"processed_data/faces\")\n",
    "    landmarks_dir = os.path.join(base_dir, \"processed_data/landmarks\")\n",
    "    \n",
    "    # First command: Extract raw video data\n",
    "    cmd1 = (\n",
    "        f\"python extract_raw_video_data.py \"\n",
    "        f\"--source_folder {video_dir}/ \"\n",
    "        f\"--audio_target_folder {audio_dir}/ \"\n",
    "        f\"--frames_target_folder {frames_dir}/ \"\n",
    "        f\"--extract_frames True\"\n",
    "    )\n",
    "    subprocess.run(cmd1, shell=True, check=True)\n",
    "    \n",
    "    # Process each video\n",
    "    for video_file in video_files:\n",
    "        video_name = os.path.splitext(video_file)[0]  # Remove .mp4 extension\n",
    "        \n",
    "        # Create faces directory\n",
    "        os.makedirs(faces_dir, exist_ok=True)\n",
    "        \n",
    "        # Second command: Extract cropped faces\n",
    "        cmd2 = (\n",
    "            f\"python extract_cropped_faces.py \"\n",
    "            f\"--from_dir_prefix {frames_dir}/{video_name} \"\n",
    "            f\"--output_dir_prefix {faces_dir}/{video_name}/\"\n",
    "        )\n",
    "        subprocess.run(cmd2, shell=True, check=True)\n",
    "        \n",
    "        # Resize faces to 256x256\n",
    "        faces_video_dir = os.path.join(faces_dir, video_name)\n",
    "        print(f\"Resizing images in {faces_video_dir} to 256x256...\")\n",
    "        resize_images_to_256x256(faces_video_dir)\n",
    "        \n",
    "        # Create landmarks directory\n",
    "        os.makedirs(landmarks_dir, exist_ok=True)\n",
    "        \n",
    "        # Third command: Extract frame landmarks\n",
    "    cmd3 = (\n",
    "        f\"python extract_frame_landmarks.py \"\n",
    "        f\"--from_dir {frames_dir} \"\n",
    "        f\"--lmd_output_dir {landmarks_dir}/\"\n",
    "    )\n",
    "    subprocess.run(cmd3, shell=True, check=True) \n",
    "\n",
    "def main(num_videos=1):\n",
    "    # Read video URLs from HDTF dataset\n",
    "    with open(video_url_path, 'r', encoding='utf-8-sig') as f:\n",
    "        lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "    if not lines:\n",
    "        print(f\"No videos found in {video_url_path}\")\n",
    "        return\n",
    "\n",
    "    if num_videos < 1:\n",
    "        print(f\"Invalid num_videos: {num_videos}. Must be at least 1.\")\n",
    "        return\n",
    "\n",
    "    total_videos = len(lines)\n",
    "    if num_videos > total_videos:\n",
    "        print(f\"Requested {num_videos} videos, but only {total_videos} available. Processing all available videos.\")\n",
    "        num_videos = total_videos\n",
    "\n",
    "    print(f\"Processing {num_videos} HDTF videos...\")\n",
    "    successful_videos = 0\n",
    "    all_video_files = []\n",
    "\n",
    "    for line_num in range(total_videos):\n",
    "        if successful_videos >= num_videos:\n",
    "            break\n",
    "        parts = lines[line_num].split()\n",
    "        if len(parts) >= 2:\n",
    "            video_name, url = parts[0], parts[1]\n",
    "            video_files = process_hdtf_video(video_name, url)\n",
    "            if video_files:\n",
    "                successful_videos += 1\n",
    "                all_video_files.extend(video_files)\n",
    "                print(f\"Successfully processed video {successful_videos}/{num_videos}\")\n",
    "            else:\n",
    "                print(f\"Skipping failed video {video_name}, trying next...\")\n",
    "\n",
    "    if not all_video_files:\n",
    "        print(\"No videos were successfully processed. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Process all clips through the pipeline\n",
    "    print(\"Processing videos through pipeline...\")\n",
    "    process_videos(all_video_files, base_path)\n",
    "    print(\"Processing complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        subprocess.run(\"yt-dlp --version\", shell=True, check=True)\n",
    "        subprocess.run(\"ffmpeg -version\", shell=True, check=True)\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"Please install the following dependencies:\")\n",
    "        print(\"  - yt-dlp: 'pip install yt-dlp'\")\n",
    "        print(\"  - ffmpeg: Install via your package manager (e.g., 'sudo apt install ffmpeg')\")\n",
    "        exit(1)\n",
    "\n",
    "    num_videos_to_process = 1  # Change this to process more videos\n",
    "    main(num_videos=num_videos_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7503442-f4b9-4a01-9f62-09c5971065a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
